{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Redact PHI using Google Cloud DLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJJG8CvZLXKI",
        "outputId": "4fb6aed1-c118-4df2-cb38-7b95d0cb9dbc"
      },
      "outputs": [],
      "source": [
        "!pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 --quiet\n",
        "!pip install google-cloud-dlp google-api-core --quiet\n",
        "!pip install jdc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tnMBoy6KsGCN"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "import os\n",
        "import logging\n",
        "from google.cloud import dlp_v2\n",
        "import pandas as pd\n",
        "import jdc\n",
        "from collections.abc import Sequence, Mapping\n",
        "from typing import Final, Union\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EThFWFZsK9t"
      },
      "source": [
        "## CSV to JSONL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzGDAuupLVmN"
      },
      "outputs": [],
      "source": [
        "directory : Path = Path('/content/drive/MyDrive')\n",
        "input_csv_path : Path = directory / 'rx_refill_or_change_request_evals.csv'\n",
        "output_jsonl_path : Path = directory / 'rx_refill_or_change_request_evals.jsonl'\n",
        "\n",
        "with open(input_csv_path, newline='', encoding='utf-8') as csvfile, open(output_jsonl_path, 'w', encoding='utf-8') as jsonlfile:\n",
        "    reader : csv.DictReader[str, str] = csv.DictReader(csvfile)\n",
        "\n",
        "    for idx, row in enumerate(reader):\n",
        "        llm_label : str = row['LLM_LABEL'].strip().lower()\n",
        "        if llm_label not in {'true', 'false'}:\n",
        "            continue\n",
        "\n",
        "        json_line : Mapping[str, str] = {\n",
        "            \"prompt\": row['MESSAGE_TEXT'],\n",
        "            \"completion\": 1 if llm_label == \"true\" else 0\n",
        "        }\n",
        "        jsonlfile.write(json.dumps(json_line) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwY8xqyls4nx"
      },
      "source": [
        "## Setup Google API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FHnfLAIerKb8"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/drive')\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = directory / 'upbeat-arch-463922-n3-8a21012ce142.json'\n",
        "PROJECT_ID : Final[str] = \"upbeat-arch-463922-n3\"\n",
        "LOCATION : Final[str] = \"global\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tdd-V6aXDumX"
      },
      "outputs": [],
      "source": [
        "logging.getLogger('google').setLevel(logging.ERROR)\n",
        "logging.getLogger('googleapiclient').setLevel(logging.ERROR)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger : logging.Logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obh8LsCttKX0"
      },
      "source": [
        "# Redactor Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eERKyQRiBZ6V"
      },
      "outputs": [],
      "source": [
        "class GoogleDLPPHIRedactor:\n",
        "    def __init__(self, project_id: str, location: str = \"global\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            project_id: The ID of the Google Cloud project to use.\n",
        "        \"\"\"\n",
        "        self.project_id : str = project_id\n",
        "        self.dlp_client : dlp_v2.DlpServiceClient = dlp_v2.DlpServiceClient()\n",
        "        self.parent : str = f\"projects/{project_id}/locations/{location}}\"\n",
        "\n",
        "        # Rate limiting: max 10 requests per second\n",
        "        # .12s between calls = ~8 calls/second (safe margin)\n",
        "        self.min_delay : np.half = .12 \n",
        "        self.last_call_time : np.half = 0\n",
        "\n",
        "        self.builtin_info_types : Sequence[Mapping[str, str]] = [\n",
        "            {\"name\": \"PERSON_NAME\"},\n",
        "            {\"name\": \"PHONE_NUMBER\"},\n",
        "            {\"name\": \"EMAIL_ADDRESS\"},\n",
        "            {\"name\": \"DATE\"},\n",
        "            {\"name\": \"US_SOCIAL_SECURITY_NUMBER\"},\n",
        "            {\"name\": \"LOCATION\"},\n",
        "        ]\n",
        "\n",
        "        self.custom_info_types : Sequence[Mapping[str, str]] = [\n",
        "            {\n",
        "                \"info_type\": {\"name\": \"CUSTOM_MEDICAL_RECORD\"},\n",
        "                \"regex\": {\"pattern\": r\"MRN[:\\s]?\\d{6,10}\"},\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        self.default_replacements : Mapping[str, str] = {\n",
        "            \"PERSON_NAME\": \"[NAME]\",\n",
        "            \"PHONE_NUMBER\": \"[PHONE]\",\n",
        "            \"EMAIL_ADDRESS\": \"[EMAIL]\",\n",
        "            \"DATE\": \"[DATE]\",\n",
        "            \"US_SOCIAL_SECURITY_NUMBER\": \"[SSN]\",\n",
        "            \"LOCATION\": \"[LOCATION]\",\n",
        "            \"CUSTOM_MEDICAL_RECORD\": \"[MRN]\"\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%add_to GoogleDLPPHIRedactor\n",
        "def _rate_limit(self):\n",
        "    \"\"\"Ensure calls don't exceed API rate limits\"\"\"\n",
        "    elapsed np.timedelta64 = time.time() - self.last_call_time\n",
        "    if elapsed < self.min_delay:\n",
        "        time.sleep(self.min_delay - elapsed)\n",
        "    self.last_call_time = time.time()\n",
        "\n",
        "def redact_phi(self, text: str, exclude_categories: Sequence[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Redact PHI with selective category exclusion\n",
        "\n",
        "    Args:\n",
        "        text: The text to redact\n",
        "        exclude_categories: List of category names to NOT redact (leave original)\n",
        "                            e.g., ['DATE', 'PERSON_NAME'] will leave dates and names unredacted\n",
        "\n",
        "    Returns:\n",
        "        Redacted text with excluded categories left untouched\n",
        "    \"\"\"\n",
        "    self._rate_limit()\n",
        "\n",
        "    if exclude_categories is None:\n",
        "        exclude_categories = []\n",
        "\n",
        "    try:\n",
        "        transformations : Sequence[Mapping[str, str]] = []\n",
        "        categories_to_redact : Mapping[str, str] = {}\n",
        "\n",
        "        for category, replacement in self.default_replacements.items():\n",
        "            if category not in exclude_categories:\n",
        "                categories_to_redact[category] = replacement\n",
        "\n",
        "        for info_type, replacement in categories_to_redact.items():\n",
        "            transformations.append({\n",
        "                \"info_types\": [{\"name\": info_type}],\n",
        "                \"primitive_transformation\": {\n",
        "                    \"replace_config\": {\"new_value\": {\"string_value\": replacement}}\n",
        "                }\n",
        "            })\n",
        "\n",
        "        deidentify_config : Mapping[str, str] = {\n",
        "            \"info_type_transformations\": {\"transformations\": transformations}\n",
        "        }\n",
        "\n",
        "        inspect_config : Mapping[str, str] = {\n",
        "            \"info_types\": self.builtin_info_types,\n",
        "            \"custom_info_types\": self.custom_info_types,\n",
        "            \"min_likelihood\": dlp_v2.Likelihood.POSSIBLE,\n",
        "        }\n",
        "\n",
        "        response : dlp_v2.DeidentifyContentResponse = self.dlp_client.deidentify_content(\n",
        "            request={\n",
        "                \"parent\": self.parent,\n",
        "                \"deidentify_config\": deidentify_config,\n",
        "                \"inspect_config\": inspect_config,\n",
        "                \"item\": {\"value\": text},\n",
        "            }\n",
        "        )\n",
        "\n",
        "        return response.item.value\n",
        "\n",
        "    except Exception as e:\n",
        "        sys.stderr.write(f\"Error redacting text: {e}\\n\")\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%add_to GoogleDLPPHIRedactor\n",
        "def process_jsonl_file(self, input_file : Path, output_file : Path, exclude_categories : Sequence[str] = None):\n",
        "    \"\"\"\n",
        "    Process JSONL with selective redaction\n",
        "\n",
        "    Args:\n",
        "        input_file: Path to input JSONL file\n",
        "        output_file: Path to output JSONL file\n",
        "        exclude_categories: List of categories to leave unredacted\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as fin, open(output_file, 'w') as fout:\n",
        "        for i, line in enumerate(fin, 1):\n",
        "            sample : Mapping[str, Union[str, Mapping[str, bool]]] = json.loads(line.strip())\n",
        "            prompt : str = sample.get(\"prompt\", \"\")\n",
        "\n",
        "            if prompt:\n",
        "                sample[\"prompt\"] = self.redact_phi(prompt, exclude_categories=exclude_categories)\n",
        "\n",
        "            fout.write(json.dumps(sample) + '\\n')\n",
        "\n",
        "            if not i % 200:\n",
        "                print(f\"Processed {i} lines\")\n",
        "                if exclude_categories:\n",
        "                    print(f\"Excluding from redaction: {exclude_categories}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q4KcxAKtWu3"
      },
      "source": [
        "## Run redactor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EU7FDSV_JMzS"
      },
      "outputs": [],
      "source": [
        "redactor : GoogleDLPPHIRedactor = GoogleDLPPHIRedactor(project_id=PROJECT_ID)\n",
        "redactor.process_jsonl_file(directory / 'rx_refill_or_change_request_evals.jsonl',\n",
        "                           directory / 'rx_refill_or_change_request_evals_redacted.jsonl',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W3HwZdPtOH3"
      },
      "source": [
        "## Custom data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_data : Sequence[Mapping[str, str]] = [\n",
        "    {\"prompt\": \"Zepbound 7.5 mg. The date of my last dose is 5/26. No side effects. My preferred pharmacy is 208 S Akard St # PC08 Dallas, TX 75202 0 0 Phone (214) 741-4912 Fax (401) 770-7108\"},\n",
        "    {\"prompt\": \"Hi! I have been trying to put in a request for a refill via Lilly direct and haven't heard back. Just following up as I have no more medication. Thank you!\"},\n",
        "    {\"prompt\": \"Hello Dr Russell! I hope you had some good time off! I am requesting, please, Zepbound refills, with the possible option of going up in dosage? I still have a pen injectable remaining, so I'm good to discuss as you get back into office the first week of June. I went on that cruise and feel I've lost momentum and am having cravings for sweets, especially at night. No other side effects. Thanks so much!\"},\n",
        "    {\"prompt\": \"Hi, Franky! My insurance recently changed (again). I have one more dose of my medication before I need to refill, but I know PAs can take some time to go through. Would you please ask Dr. Gause to submit when she has a moment?\"},\n",
        "    {\"prompt\": \"Hi Dr. Smith, I am on my last pen of Zepbound 7.5 and require a refill. I am requesting to go up to the next dosage.\"},\n",
        "    {\"prompt\": \"Hi Ms Harris, I hope you are doing well, CVS sent me letter to tell me that Zepbound as of July 1st my insurance not going to cover these medication and told me that either ORLISTAT, QSYMIA, SAXENDA, Wagovy , anyone of this will be covered by my insurance , please if you can send the refill to CVS one more time and after the July 1st we have to choose which one, do you think!\"},\n",
        "    {\"prompt\": \"Hi Dr. Madriaga. Walgreens isn't showing that my Rx has any refills. Could you take a look? (If you wanted me to get more blood tests first I can do that. I was thinking I should get the next blood tests right before leaving for Paris.)\"},\n",
        "    {\"prompt\": \"The pharmacy asked either up the dose or override since the insurance company is saying waiting your approval\"},\n",
        "    {\"prompt\": \"Good afternoon, will you please refill the prescription for the 12.5mg. I took the last dose on Sunday\"}\n",
        "]\n",
        "\n",
        "with open('custom_data.jsonl', 'w') as f:\n",
        "    for item in sample_data:\n",
        "        f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "print(\"Medical data JSONL file created: custom_data.jsonl\")\n",
        "\n",
        "redactor : GoogleDLPPHIRedactor = GoogleDLPPHIRedactor(project_id=PROJECT_ID)\n",
        "redactor.process_jsonl_file('custom_data.jsonl',\n",
        "                           \"custom_data_redacted.jsonl\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J949LaAtHsCm"
      },
      "source": [
        "## Unmask selected categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AVAOGJLlHqqA"
      },
      "outputs": [],
      "source": [
        "def create_efficient_redacted_dataset(input_file : Path, output_file : Path,\n",
        "                                    total_samples : np.uintc = 13000,\n",
        "                                    negative_ratio : np.half = 0.75,\n",
        "                                    exclude_categories : Sequence[str] = None):\n",
        "    df : pd.DataFrame = pd.read_json(input_file, lines=True)\n",
        "\n",
        "    n_negatives : np.uintc = int(total_samples * negative_ratio)\n",
        "    n_positives : np.uintc = int(total_samples * (1 - negative_ratio))\n",
        "\n",
        "    sample_0 : pd.DataFrame = df[df['completion'] == 0].sample(n=n_negatives, random_state=42)\n",
        "    sample_1 : pd.DataFrame = df[df['completion'] == 1].sample(n=n_positives, random_state=42)\n",
        "    sampled_df : pd.DataFrame = pd.concat([sample_0, sample_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    redactor : GoogleDLPPHIRedactor = GoogleDLPPHIRedactor(project_id=PROJECT_ID)\n",
        "    print(f\"Excluding categories: {exclude_categories if exclude_categories else 'None (redacting all)'}\")\n",
        "\n",
        "    redacted_samples : Sequence[Mapping[str, Union[str, Mapping[str, bool]]]] = []\n",
        "    for i, (_, row) in enumerate(sampled_df.iterrows(), 1):\n",
        "        original_prompt : str = row['prompt']\n",
        "        redacted_prompt : str = redactor.redact_phi(original_prompt, exclude_categories=exclude_categories)\n",
        "        data : Mapping[str, Union[str, Mapping[str, bool]]] = {\n",
        "            'prompt': redacted_prompt,\n",
        "            'completion': {\"refill request\": row['completion']}\n",
        "        }\n",
        "        redacted_samples.append(data)\n",
        "\n",
        "        if not i % 500:\n",
        "            print(f\"Processed {i}/{len(sampled_df)} samples.\")\n",
        "    print(f\"Saving to {output_file}.\")\n",
        "    with open(output_file, 'w') as outfile:\n",
        "        for sample in redacted_samples:\n",
        "            outfile.write(json.dumps(sample) + '\\n')\n",
        "    return output_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "collapsed": true,
        "id": "NWqzBkj3NixN",
        "outputId": "4b3d014c-dcca-4279-ad43-fcdc39bfe606"
      },
      "outputs": [],
      "source": [
        "categories_to_unmask : Sequence[str] = [\n",
        "    'PERSON_NAME', 'PHONE_NUMBER',\n",
        "    'EMAIL_ADDRESS',\n",
        "    'DATE', 'US_SOCIAL_SECURITY_NUMBER', 'LOCATION',\n",
        "    'CUSTOM_MEDICAL_RECORD'\n",
        "]\n",
        "\n",
        "for category in categories_to_unmask:\n",
        "    output_file : Path = directory / f\"efficient_unmasked_{category.lower()}_13000_75.jsonl\"\n",
        "\n",
        "    create_efficient_redacted_dataset(\n",
        "        input_file='/content/drive/MyDrive/rx_refill_or_change_request_evals.jsonl',\n",
        "        output_file=output_file,\n",
        "        exclude_categories=[category]\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
